# import the necessary packages
from pyimagesearch.iou import compute_iou
from pyimagesearch import config
from bs4 import BeautifulSoup
from imutils import paths
import cv2
import os




for x in range(1, 2):
	print("Processing images from subject {}".format(x))
	#imagePaths = list(paths.list_images(os.path.sep.join([config.ORIG_IMAGES, "Subject{}".format(x)])))
	imageBasePath = os.path.sep.join([config.ORIG_IMAGES, "Subject{}".format(x)])
	allImages = []
	allLabels = []
	gtBoxes = []
	
	#get annotations from text file
	annotFile = os.path.sep.join([config.ANNOT_BASE_PATH, "Subject{}.txt".format(x)])

	#opens and goes through file
	f = open(annotFile, "r")
	next(f)
	for line in f:
		#get the image name
		currentLine = line.split(",")
		currentImage = currentLine[0][currentLine[0].rfind("Color\\")+6:]
		allImages.append(currentImage)
		imageFile = os.path.sep.join([imageBasePath, currentImage])

		#get the ground truth boxes
		index = 0
		count = 0
		label = ""
		for y in currentLine[2:]:
			#if 2 boxes found already, skip the rest
			if count == 2:
				break

			# change the str into a list
			y = y.replace('[', '').replace(']', '').split()
			
            # change numbers from str to float
			for i in range(len(y)):
				y[i] = int(float(y[i]))
				
			#format is [x, y, w, h]
			#if width and height are zero, it's an empty bounding box
			if ((y[2] == 0) & (y[3] == 0)):
				index += 1
				continue

			# exclude two handed gestures
			if index > 25:
				allImages.pop()
				break

			#getting label of img
			if 0 <= index <= 1:
				label = "punch"
			elif 2 <= index <= 3:
				label = "one"
			elif 4 <= index <= 5:
				label = "two"
			elif 6 <= index <= 7:
				label = "three"
			elif 8 <= index <= 9:
				label = "four"
			elif 10 <= index <= 11:
				label = "five"
			elif 12 <= index <= 13:
				label = "six"
			elif 14 <= index <= 15:
				label = "seven"
			elif 16 <= index <= 17:
				label = "eight"
			elif 18 <= index <= 19:
				label = "nine"
			elif 20 <= index <= 21:
				label = "span"
			elif 22 <= index <= 25:
				label = "horiz"


			allLabels.append(label)

			#convert ground truth boxes to (startX, startY, endX, endY)
			gt = (y[0], y[1], y[0] + y[2], y[1] + y[3])
			gtBoxes.append(gt)
			index += 1
			count += 1
	f.close()

	for imageName in allImages[:4]:
		# get and read image
		imagePath = os.path.sep.join([imageBasePath, imageName])
		
		print(imagePath)

		# load the input image from disk
		image = cv2.imread(imagePath)

		"""
		# run selective search on the image and initialize our list of
		# proposed boxes
		ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
		ss.setBaseImage(image)
		ss.switchToSelectiveSearchFast()
		rects = ss.process()
		proposedRects= []
		
		# loop over the rectangles generated by selective search
		for (x, y, w, h) in rects:
			# convert our bounding boxes from (x, y, w, h) to (startX,
			# startY, startX, endY)
			proposedRects.append((x, y, x + w, y + h))
		"""

		
		gtCount = 0

		for gtBox in gtBoxes[gtCount:gtCount + 2]:
			# compute the intersection over union between the two
			# boxes and unpack the ground-truth bounding box
			num = 0
			filename = "{:05d}.png".format((num))

			(gtStartX, gtStartY, gtEndX, gtEndY) = gtBox
			roi = image[gtStartY:gtEndY, gtStartX:gtEndX]

			cv2.imshow("RoI", roi)
			cv2.waitKey(0)

			outputPath = os.path.sep.join([config.BASE_PATH, allLabels[num], filename])

			# check to see if both the ROI and output path are valid
			if roi is not None and outputPath is not None:
				# resize the ROI to the input dimensions of the CNN
				# that we'll be fine-tuning, then write the ROI to
				# disk
				roi = cv2.resize(roi, config.INPUT_DIMS,
					interpolation=cv2.INTER_CUBIC)
				cv2.imwrite(outputPath, roi)
			gtCount += 1
			num += 1
	
	